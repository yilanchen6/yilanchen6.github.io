---
layout: default
---


<!-- later try:
https://david-abel.github.io/index.html -->



## About Me

<!-- <figure>
<img src="/images/chenyilan.jpg" align="left" width="200px" style="margin-right:20px" alt="Yilan's picture" title="2019 at Beijing."/>
<figcaption>2019 at Beijing.</figcaption>
</figure> -->

<img src="/images/chenyilan3.jpg" align="left" width="200px" style="margin-right:20px" alt="Yilan's picture" title="Yilan."/>
I am a Ph.D. student in [Computer Science and Engineering Department](https://cse.ucsd.edu/) at University of California San Diego (UCSD). I also work closely with Prof. [Taiji Suzuki](https://ibis.t.u-tokyo.ac.jp/suzuki/) at University of Tokyo.
<!-- I'm fortunate to be advised by Prof. [Tsui-Wei (Lily) Weng](https://lilywenglab.github.io/).  -->
I received my M.S. degree from UCSD and B.E. degree from [Xi'an Jiaotong University](http://en.xjtu.edu.cn/). 
<!-- Here is my [CV](/files/CV_Yilan_Chen.pdf).  -->

[[Google Scholar]](https://scholar.google.com/citations?user=6wmzpRIAAAAJ&hl=en) 
[[Twitter]](https://twitter.com/yilanchen06)
[[Zhihu]](https://www.zhihu.com/people/yilan-24-8/posts)



<!-- I am interning at [deep learning theory team](https://aip.riken.jp/labs/generic_tech/deep_learn_theory/) in RIKEN AIP advised by Prof. [Taiji Suzuki](https://ibis.t.u-tokyo.ac.jp/suzuki/) this summer. -->


<br clear="left"/>



## Research Interests


<!-- My current research interests are theoretical machine learning and its applications, with a focus on deep learning theory (optimization, generalization, and robustness). My research goal is to establish theoretical foundations for modern deep learning models and develop principled algorithms for real-world applications. -->

<!-- My research aims to bridge the gap between theory and applications of machine learning by establishing theoretical foundations for modern deep learning models and developing principled algorithms for real-world applications. -->

My current research interests are theoretical machine learning and its applications, especially
- Deep learning theory (optimization, generalization, robustness)
- Large language models and foundation models
- Principled algorithms for real-world applications

Feel free to drop me an email if you would like to collabrate or have a discussion!
<!-- - Reinforcement learning theory -->




## Publications

### Machine Learning Theory
- [Provable and Efficient Dataset Distillation for Kernel Ridge Regression.](https://openreview.net/pdf?id=WI2VpcBdnd)<br>
**Yilan Chen**, Wei Huang, Tsui-Wei Weng.<br>
Thirty-eighth Conference on Neural Information Processing Systems (NeurIPS 2024).

- [Cross-Task Linearity Emerges in the Pretraining-Finetuning Paradigm.](https://arxiv.org/pdf/2402.03660.pdf)<br>
Zhanpeng Zhou<sup>1</sup>, Zijun Chen<sup>1</sup>, **Yilan Chen**, Bo Zhang, Junchi Yan.<br>
Forty-first International Conference on Machine Learning (ICML 2024).

- [Analyzing Generalization of Neural Networks through Loss Path Kernels.](https://openreview.net/pdf?id=8Ba7VJ7xiM) [[code]](https://github.com/Trustworthy-ML-Lab/NN-LPK) [[slides]](/files/LPK.pdf) [[poster]](/files/LPK_poster.pdf) [[video]](https://nips.cc/virtual/2023/poster/72664)<br>
**Yilan Chen**, Wei Huang, Hao Wang, Charlotte Loh, Akash Srivastava, Lam M. Nguyen, Tsui-Wei Weng.<br>
Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023).

- [Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection.](https://openreview.net/pdf?id=nEX2q5B2RQ)<br>
Wei Huang<sup>1</sup>, Chunrui Liu<sup>1</sup>, **Yilan Chen**, Richard Yi Da Xu, Miao Zhang, Tsui-Wei Weng.<br>
Transactions on Machine Learning Research (TMLR 2023).

- [On the Equivalence between Neural Network and Support Vector Machine.](https://arxiv.org/pdf/2111.06063.pdf) [[code]](https://github.com/leslie-CH/equiv-nn-svm)[[slides]](/files/SVM_Slides.pdf)[[poster]](/files/SVM_NeurIPS_2021_poster.pdf)[[video]](https://neurips.cc/virtual/2021/poster/27419)<br>
**Yilan Chen**, Wei Huang, Lam M. Nguyen, Tsui-Wei Weng.<br>
Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021).


### Interpretable Machine Learning
- [The Importance of Prompt Tuning for Automated Neuron Explanations.](https://arxiv.org/pdf/2310.06200.pdf)<br>
Justin Lee<sup>1</sup>, Tuomas Oikarinen<sup>1</sup>, Arjun Chatha, Keng-Chi Chang, **Yilan Chen**, Tsui-Wei Weng.<br>
NeurIPS 2023 Workshop on Attributing Model Behavior at Scale.

- [Quantifying the Knowledge in a DNN to Explain Knowledge Distillation for Classification.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864081)<br>
Quanshi Zhang<sup>1</sup>, Xu Cheng<sup>1</sup>, **Yilan Chen**, Zhefan Rao.<br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2023).

- [Explaining Knowledge Distillation by Quantifying the Knowledge.](https://arxiv.org/pdf/2003.03622.pdf)<br>
Xu Cheng, Zhefan Rao<sup>2</sup>, **Yilan Chen**<sup>2</sup>, Quanshi Zhang.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020).



<!-- ## Preprint -->




## Talks
Analyzing Neural Networks through Equivalent Kernels [[slides]](/files/LPK_SOCAMS.pdf)
- Aug 2024 - [RIKEN AIP â€“ SJTU CS Joint Workshop on Machine Learning and Brain-like Intelligence](https://tensorworkshop.github.io/RIKENAIP_SJTUCS2024/)
- Apr 2024 - [Southern California Applied Mathematics Symposium (SOCAMS 2024)](https://www.socams.org/home)

Analyzing Generalization of Neural Networks through Loss Path Kernels [[slides]](/files/LPK.pdf)
- Jan 2024 - ByteDance
- Nov 2023 - AI TIME 





<!-- ## Notes
- [A Note about NTK Derivation](/files/ntk_derivation.pdf)
- [Some Derivations and Proofs about Linearized Networks](/files/linearized_network.pdf) -->


<!-- **<font size='5'>Projects</font>**
* [Prototype Selection for Nearest Neighbor](/files/Prototype_Selection.pdf)
* [Coordinate Descent](/files/coord_desc.pdf) -->




## Teaching
- [DSC 212: Probability and Statistics](https://sites.google.com/ucsd.edu/dsc212f24/home), TA, Fall 2024
- [DSC 140B: Representation Learning](https://lilywenglab.github.io/DSC-140B-SP24/), TA, Spring 2024
- [DSC 210: Numerical Linear Algebra](https://lilywenglab.github.io/DSC-210-fa23/), TA, Fall 2023
- [DSC 291: Trustworthy Machine Learning](https://lilywenglab.github.io/dsc-291-sp23/), Tutor, Fall 2021






<!-- ## Courses
- Machine Learning:
  - CSE 250A Probabilistic Reason & Learning  A+
  - CSE 251A ML: Learning Algorithms  A+
  - CSE 251C ML: Machine Learning Theory  A
  - CSE	252A Computer Vision I  A+
  - CSE	257  Search and Optimization A

- Math:
  - MATH 245A	Convex Analysis & Optimization I  A
  - MATH 245B	Convex Analysis & Optimization II  A
  - ECE	269   Linear Algebra and Application A
  - MATH 281A Mathematical Statistics ongoing -->






## Professional Service
- Conference Reviewer: ICML, NeurIPS, ICLR
<!-- - Journal Reviewer: Journal of Optimization Theory and Applications (JOTA) -->
<!-- - Program Committee: AAAI 2023 Workshop MLmDS -->




## Contact

University of California San Diego, La Jolla, CA<br>
Email: yic031 [at] ucsd.edu
